# -*- coding: utf-8 -*-
"""Reproducible Research Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/orkhan-amrullayev/7d878fd1b167f22fe6545f89a0ab1afe/reproducible-research-project.ipynb

edited by Orkhan
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn.model_selection import train_test_split
from random import random
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier
from matplotlib import pyplot



#Importing the libraries 
import pandas as pd

df = pd.read_csv('/content/telco_churn (1).csv')

from google.colab import drive
drive.mount('/content/drive')

#Importing the datasetr
df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/telco_churn.csv")

df.head()

df.describe()

# Find null values in the dataset
df.isnull().any(axis=1)

# Find null values in the dataset
df.dropna(axis = 1, how ='any', thresh = None, subset = None, inplace=False)
df.dropna(axis = 0, how ='any', thresh = None, subset = None, inplace=False)

# Find null values in the dataset
df.isnull().any(axis=0)

"""# **Analyzing the categorical features**"""

categorical_features=[feature for feature in df.columns if ((df[feature].dtypes=='O') )]
plt.figure(figsize=(40,280), facecolor='white')
plotnumber =1
for categorical_feature in categorical_features:
    ax = plt.subplot(15,3,plotnumber)
    sns.countplot(y=categorical_feature,data=df)
    plt.xlabel(categorical_feature)
    plt.title(categorical_feature)
    plotnumber+=1
plt.show()





"""# Findings


"""

df['Churn Value'].value_counts()

df[df['Churn Value'] == 0.0].sample(1869)





"""<h3>Correlation matrix</h3>"""

fig, ax = plt.subplots(figsize=(20,20)
sns.heatmap(df.corr(), annot=True, linewidths=.5, ax=ax)

"""Outcome of Correlation Matrix

# Check the Data set is balanced or not based on target values in classification
"""





"""**Integer encoding**"""

#Identify the categorical columns in the dataset
obj_df = df.select_dtypes(include=['object']).copy()
obj_df.head()

#Encoding the categorical values ( Integer encoding )
new_df = df.apply(LabelEncoder().fit_transform)
new_df.head()

#Randomization of the dataset
np.random.seed(1000)

# Seperating the Features and Target Columns 
df_feat = new_df[new_df.columns[0:-1]] # Feature columns 
df_head = new_df[new_df.columns[len(new_df.columns)-1]]  # Target variable



"""## Data Normalization"""

# Feature Scalling using Sklearn StandardScaler function
scaler = StandardScaler()
StandardScaler(copy=True,with_mean=True,with_std=True)
scaler.fit(df_feat)
scaled_features = scaler.transform(df_feat)
df_scaled = pd.DataFrame(scaled_features,columns=df_feat.columns)
df_scaled.head()

df_scaled.dtypes





"""## Feature Importance Analysis"""

##Feature Selection using XGBClassifier
model = XGBClassifier()
# fit the model
model.fit(df_scaled,df_head)
# get importance
importance = model.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
	print('Feature: %0d, Score: %.5f' % (i,v))
# plot feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()
